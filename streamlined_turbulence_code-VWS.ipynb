{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9476eee7-85ed-49ef-891a-14b6a30bdbfd",
   "metadata": {},
   "source": [
    "# This notebook processes, evaluates, and plots Clear Air Turbulence indices for BARPA-R and BARRA-R \n",
    "# VWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a38098-5c9b-4664-b4a6-aee05730e1aa",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad60213-5b21-4927-9b83-6d48956a171a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "import intake\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import xesmf as xe\n",
    "import inspect\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from turbulence_AUSCAT.cat_indices import calc_turbulence_indices, windspeed, VWS\n",
    "from xarray.groupers import SeasonResampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"flox\").setLevel(logging.WARNING)\n",
    "\n",
    "from plotting_maps.acs_plotting_maps import plot_acs_hazard_multi, plot_acs_hazard, plot_data, cmap_dict, regions_dict\n",
    "from matplotlib import colors, cm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "# ProgressBar().register()\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "# ensure lots of resources are requested. Eg 28 cores\n",
    "# client = Client(threads_per_worker=120, n_workers=8)\n",
    "# client = Client(threads_per_worker=4, n_workers=2) \n",
    "# client = Client(threads_per_worker=6, n_workers=2)\n",
    "\n",
    "# client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b32e2a-f432-4c3d-881c-58c523d83531",
   "metadata": {},
   "source": [
    "# Choose index to process and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c984dd32-108c-47b3-9d46-7d9bfeebab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_lat_slice = slice(-50,-25)\n",
    "lon_slice = slice(90,195)\n",
    "\n",
    "baseline_time_range = np.arange(1990,2009+1)\n",
    "baseline_time_slice = slice(\"1990\", \"2009\")\n",
    "\n",
    "P=200\n",
    "p=P\n",
    "p0 = P-50\n",
    "p1 = P+50\n",
    "P0 = 1000\n",
    "step_size=  0.1545\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab1bad86-33ab-48c9-a7c8-33d92d686189",
   "metadata": {},
   "outputs": [],
   "source": [
    "turbulence_index_list = [\"VWS\"]\n",
    "turbulence_index = turbulence_index_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5917ed-1fa9-47ee-85c0-df481a1521b6",
   "metadata": {},
   "source": [
    "# Prepare BARRA-R data for baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3424a58f-818d-438a-b795-e9829110285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = xr.open_dataset(\"/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6e4da5-b778-45bd-b531-001e9f4ac7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_target = xr.open_dataset(\"/g/data/py18/BARPA/output/CMIP6/DD/AUS-15/BOM/ACCESS-CM2/historical/r4i1p1f1/BARPA-R/v1-r1/6hr/ua200/v20231001/ua200_AUS-15_ACCESS-CM2_historical_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_196001-196012.nc\")\\\n",
    ".drop_vars(\"pressure\").chunk({\"time\":120, \"lat\":-1, \"lon\":-1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ed0570-07ce-4ab5-bdb7-ef5ded7011b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "CPU times: user 930 ms, sys: 279 ms, total: 1.21 s\n",
      "Wall time: 2.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# best with one thread per worker\n",
    "VARU = \"wnd_ucmp\"\n",
    "VARV = \"wnd_vcmp\"\n",
    "VART = \"air_temp\"\n",
    "VARZ = \"geop_ht\"\n",
    "\n",
    "barra_vars = {\"wnd_ucmp\":\"ua\", \"wnd_vcmp\": \"va\", \"air_temp\":\"ta\", \"geop_ht\":\"zg\"}\n",
    "\n",
    "# start and end for BARRA-R specifically\n",
    "lat_min, lat_max, lon_min, lon_max = (ds_target[\"lat\"].values[0], ds_target[\"lat\"].values[-1], \n",
    "                                      ds_target[\"lon\"].values[0], ds_target[\"lon\"].values[-1])\n",
    "regridder=None\n",
    "\n",
    "def _preprocess(ds):\n",
    "    ds = ds.drop_vars( [\"latitude_longitude\"],)\\\n",
    "            .sel({\"latitude\": slice(lat_min-0.2 , lat_max+0.2), \"longitude\":slice(lon_min-0.2 , lon_max+0.2)})\\\n",
    "            .sel({\"pressure\":[100, 150, 200, 250, 300,]},  method = \"nearest\")\n",
    "            # .sel({\"pressure\":[p0,p,p1]},  method = \"nearest\")\n",
    "    try:\n",
    "        ds = ds.drop_vars([\"forecast_period\", \"forecast_reference_time\",])\n",
    "    except:\n",
    "        pass\n",
    "    return ds  \n",
    "\n",
    "with Client(threads_per_worker=1, n_workers=30) as client:\n",
    "    # retry loop because sometimes this loop fails (randomly?) and can be resolved by simply retrying\n",
    "    max_retries = 10\n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            ds = None\n",
    "            for VAR in [VARU, VARV, VARZ, VART]:\n",
    "                regridder = None\n",
    "                for year in baseline_time_range:\n",
    "                    new_file = f\"/scratch/v46/gt3409/BARRA-R/TMP_{barra_vars[VAR]}_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "                    if os.path.exists(new_file):\n",
    "                        print(f\"File '{new_file}' already exists.\")\n",
    "                        continue\n",
    "                        \n",
    "                    filelist = glob.glob(f\"/g/data/cj37/BARRA/BARRA_R/v1/analysis/prs/{VAR}/{year}/*/{VAR}-an-prs-PT0H-BARRA_R-v1-*T*00Z.sub.nc\")\n",
    "                    filelist.sort()\n",
    "                \n",
    "                    print(f\"open_mfdataset {VAR} {year}...\")\n",
    "                    ds = xr.open_mfdataset(filelist, preprocess=_preprocess, combine=\"nested\", concat_dim=\"time\", \n",
    "                                           parallel=True, decode_timedelta=False)\\\n",
    "                            .rename({\"latitude\":\"lat\", \"longitude\":\"lon\", VAR:barra_vars[VAR]})\\\n",
    "                            .chunk({\"pressure\":1, \"time\":120, \"lat\":-1, \"lon\":-1})\n",
    "    \n",
    "                    if regridder is None:\n",
    "                        print(\"calculate regridder...\")\n",
    "                        regridder = xe.Regridder(ds, ds_target, \"bilinear\",)\n",
    "                    print(f\"regrid and compute {year}...\")\n",
    "                    ds_regridded = regridder(ds)\n",
    "                    # for plvl in [p0, p, p1]:\n",
    "                    new_file = f\"/scratch/v46/gt3409/BARRA-R/TMP_{barra_vars[VAR]}_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"                   \n",
    "                    try:\n",
    "                        print(\"saving netcdf...\")\n",
    "                        # ds_regridded.sel({\"pressure\":plvl}, method=\"nearest\").to_netcdf(new_file)\n",
    "                        ds_regridded.to_netcdf(new_file)\n",
    "                        print(f\"Saved {new_file}\")\n",
    "                        \n",
    "                        # check\n",
    "                        ds = xr.open_dataset(new_file)\n",
    "                        nulls = ds.isel({\"pressure\":0, \"lat\":0, \"lon\":0})[barra_vars[VAR]].isnull().sum().values\n",
    "                        print(f\"nulls = {nulls} for {new_file}\")\n",
    "                        if nulls == 0:\n",
    "                            pass\n",
    "                        else:\n",
    "                            os.remove(new_file)\n",
    "                            print(f\"nulls found. Removed file: {new_file}\")\n",
    "                            break    \n",
    "                    except:\n",
    "                        # os.remove(new_file)\n",
    "                        print(f\"Problem saving {new_file}\")\n",
    "                        continue\n",
    "                    ds.close()\n",
    "                    ds_regridded.close()  \n",
    "                \n",
    "        except:\n",
    "            retry_count += 1\n",
    "            print(f\"Error. Retry count = {retry_count}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Operation failed after {max_retries} attempts.\")\n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90627692-7600-4467-aa24-d2610d4da47a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594a4026-d89d-45d7-9c18-355fb35bd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a2da6e-b2e5-48e3-a275-2fc7c6d20ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for VAR in [VARU, VARV, VARZ, VART]:\n",
    "#     print(VAR)\n",
    "#     for year in baseline_time_range:\n",
    "#         file = f\"/scratch/v46/gt3409/BARRA-R/TMP_{barra_vars[VAR]}_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "#         print(year)\n",
    "#         ds = xr.open_dataset(file)\n",
    "#         nulls = ds.isel({\"pressure\":0, \"lat\":0, \"lon\":0})[barra_vars[VAR]].isnull().sum().values\n",
    "#         if nulls == 0:\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(f\"nulls = {nulls} for {file}. Removing ...\")\n",
    "#             os.remove(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3baf896-e00e-4a47-8755-ee967b34861c",
   "metadata": {},
   "source": [
    "# Identify available BARPA-R experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3af0a83a-f4fb-4763-b1d9-b8db3c20198b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_id                                                    [BARPA-R]\n",
       "institution_id                                                     [BOM]\n",
       "version                                                      [v20231001]\n",
       "variable_id            [ta150, ta200, ta250, ua150, ua200, ua250, va1...\n",
       "table_id                                                           [6hr]\n",
       "source_id              [ACCESS-CM2, ACCESS-ESM1-5, CESM2, CMCC-ESM2, ...\n",
       "experiment_id           [historical, ssp126, ssp370, ssp585, evaluation]\n",
       "member_id                      [r4i1p1f1, r6i1p1f1, r11i1p1f1, r1i1p1f1]\n",
       "grid_label                                                      [AUS-15]\n",
       "time_range             [196001-196012, 196101-196112, 196201-196212, ...\n",
       "path                   [/g/data/py18/BARPA/output/CMIP6/DD/AUS-15/BOM...\n",
       "derived_variable_id                                                   []\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get information of available datasets\n",
    "\n",
    "cat_name = \"barpa\"\n",
    "col = intake.open_esm_datastore(f\"/g/data/lp01/collections/py3.9_dev/nci-{cat_name}.json\")\n",
    "\n",
    "var_list = [f\"{var}{pressure}\" for var in [\"ta\", \"ua\", \"va\", \"zg\"] for pressure in [P-50, P, P+50]]\n",
    "\n",
    "table_id = \"6hr\"\n",
    "scenarios = [\"historical\",\"ssp126\", \"ssp370\", \"ssp585\", \"evaluation\"]\n",
    "\n",
    "# change this query to select a subset of the data you are interested in\n",
    "query = dict(variable_id = var_list,\n",
    "             table_id = table_id,\n",
    "             experiment_id = scenarios,\n",
    "            )\n",
    "\n",
    "cat = col.search(**query)\n",
    "cat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b818cb9e-6b82-42a5-b471-bdc992d22e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_max = cat.df.groupby([\"variable_id\", \"experiment_id\", \"source_id\", \"member_id\"]).max().reset_index()\n",
    "# cat_df_max[\"index\"] = cat_df_max.variable_id + \"_\" + cat_df_max.experiment_id + \"_\" + cat_df_max.source_id + \"_\" + cat_df_max.member_id\n",
    "cat_df_max[\"index\"] = [f'{cat_df_max.iloc[i][\"experiment_id\"]}_{cat_df_max.iloc[i][\"source_id\"]}_{cat_df_max.iloc[i][\"member_id\"]}' for i in np.arange(len(cat_df_max))]\n",
    "cat_df_max = cat_df_max.set_index(\"index\")\n",
    "\n",
    "\n",
    "# indices for evaluation, historical and future groups. These will share time ranges\n",
    "i_evaluation = cat_df_max.loc[cat_df_max[\"experiment_id\"].isin([\"evaluation\"])].index\n",
    "i_historical = cat_df_max.loc[cat_df_max[\"experiment_id\"].isin([\"historical\"])].index\n",
    "i_future = cat_df_max.loc[cat_df_max[\"experiment_id\"].isin([\"ssp126\", \"ssp370\", \"ssp585\"])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a6def7-a7df-4c75-936c-141a5613d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_evaluation = ['evaluation_BARRA-R_r1i1p1f1',\n",
    "                   'evaluation_ERA5_r1i1p1f1',\n",
    "                  ]\n",
    "\n",
    "list_historical = ['historical_ACCESS-CM2_r4i1p1f1', \n",
    "                   'historical_ACCESS-ESM1-5_r6i1p1f1',\n",
    "                   'historical_CESM2_r11i1p1f1', \n",
    "                   'historical_CMCC-ESM2_r1i1p1f1',\n",
    "                   'historical_EC-Earth3_r1i1p1f1',\n",
    "                   'historical_MPI-ESM1-2-HR_r1i1p1f1',\n",
    "                   'historical_NorESM2-MM_r1i1p1f1',\n",
    "                  ]\n",
    "\n",
    "list_ssp126 = [\n",
    "                 'ssp126_ACCESS-CM2_r4i1p1f1', \n",
    "                 'ssp126_ACCESS-ESM1-5_r6i1p1f1',\n",
    "                 'ssp126_CESM2_r11i1p1f1',\n",
    "                 'ssp126_CMCC-ESM2_r1i1p1f1',\n",
    "                 'ssp126_EC-Earth3_r1i1p1f1',\n",
    "                 'ssp126_MPI-ESM1-2-HR_r1i1p1f1',\n",
    "                 'ssp126_NorESM2-MM_r1i1p1f1',\n",
    "              ]\n",
    "\n",
    "list_ssp370 = ['ssp370_ACCESS-CM2_r4i1p1f1',\n",
    "                 'ssp370_ACCESS-ESM1-5_r6i1p1f1',\n",
    "                 'ssp370_CESM2_r11i1p1f1',\n",
    "                 'ssp370_CMCC-ESM2_r1i1p1f1',\n",
    "                 'ssp370_EC-Earth3_r1i1p1f1',\n",
    "                 'ssp370_MPI-ESM1-2-HR_r1i1p1f1',\n",
    "                 'ssp370_NorESM2-MM_r1i1p1f1',\n",
    "              ]\n",
    "\n",
    "list_ssp585 = ['ssp585_ACCESS-CM2_r4i1p1f1',\n",
    "                 'ssp585_EC-Earth3_r1i1p1f1']\n",
    "\n",
    "list_future = list_ssp126 + list_ssp370 + list_ssp585"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e76436-6bea-4e04-83f6-3ceab4ded607",
   "metadata": {},
   "source": [
    "# Calculate indices from standard variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdf1e47b-a263-4459-b213-6cc922429eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dti_preprocess(ds):\n",
    "    ds = ds.drop_vars([\"crs\"])\n",
    "    # ds = ds.dropna(\"time\") # too slow\n",
    "    ds = ds.convert_calendar(\"standard\")\n",
    "    try:\n",
    "        ds = ds.expand_dims({\"pressure\":[int(ds.variable_id[2:])]})\n",
    "    except:\n",
    "        pass\n",
    "    return ds\n",
    "    \n",
    "def delayed_turbulence_index(turbulence_index=None,\n",
    "                             year=None,\n",
    "                             path = \"/g/data/py18/BARPA/output/CMIP6/DD/AUS-15/BOM\",\n",
    "                             source_id=None,\n",
    "                             experiment_id=None,\n",
    "                             member_id=None,\n",
    "                             table_id = \"6hr\", \n",
    "                             version=\"v20231001\", \n",
    "                             P=250,\n",
    "                             outfile = None,\n",
    "                             ):\n",
    "    \"\"\"Use this function to compute the turbulence indices in a delayed routine\"\"\"\n",
    "    # get a list of the variables needed for calculating this turbulence index (var_list)\n",
    "    var_list = [f\"{var}{pressure}\" for var in [\"ta\", \"ua\", \"va\", \"zg\"] for pressure in [P-50, P, P+50]]\n",
    "    dict_variables = {\"t\":\"ta\",\"u\":\"ua\",\"v\":\"va\",\"z\":\"zg\",\n",
    "                      \"p\":int(P),\"p0\":int(P-50),\"p1\":int(P+50),}\n",
    "    inverted_dict = {value: key for key, value in dict_variables.items()}\n",
    "\n",
    "    def _filename(var, pressure, source_id, experiment_id):\n",
    "        VAR = f\"{dict_variables[var]}{dict_variables[pressure]}\"\n",
    "        if source_id == \"BARRA-R\" and experiment_id == \"evaluation\":\n",
    "            filename = f\"/scratch/v46/gt3409/BARRA-R/TMP_{dict_variables[var]}_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "        else:\n",
    "            filename = f\"{path}/{source_id}/{experiment_id}/{member_id}/BARPA-R/v1-r1/{table_id}/{VAR}/{version}/\\\n",
    "{VAR}_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}01-{year}12.nc\"\n",
    "        return filename\n",
    "\n",
    "    def _open_it(file):\n",
    "        ds = xr.open_dataset(file, decode_times=True, chunks ={\"time\":-1, \"lat\":-1, \"lon\":-1})\\\n",
    "            .drop_vars([\"crs\"])\\\n",
    "            .astype(\"float32\")\\\n",
    "            .convert_calendar(\"standard\")\n",
    "\n",
    "        VAR=list(ds.variables)[0]\n",
    "        ds = ds.rename({VAR: inverted_dict[''.join(char for char in VAR if char.isalpha())]})\n",
    "        try:\n",
    "            ds = ds.expand_dims(\"pressure\")\n",
    "        except:\n",
    "            pass\n",
    "        ds[\"pressure\"] = ds[\"pressure\"].astype(\"int\")\n",
    "        return ds\n",
    "\n",
    "    turbulence_index_vars = set()\n",
    "    turbulence_index_vars.update(list(inspect.signature(globals()[turbulence_index]).parameters.keys()))\n",
    "    \n",
    "    params = turbulence_index_vars.intersection([\"t\", \"u\", \"v\", \"z\"])\n",
    "    plvls = turbulence_index_vars.intersection([\"p0\", \"p\", \"p1\", \"P0\"])\n",
    "    if len(plvls)==0:\n",
    "        plvls=set([\"p\"])\n",
    "    \n",
    "    var_list = [f\"{dict_variables[var]}{dict_variables[pressure]}\" for var in list(params) for pressure in list(plvls)]\n",
    "\n",
    "    \n",
    "    ds = xr.merge([xr.concat([_open_it(_filename(var, pressure, source_id, experiment_id)).sel({\"pressure\":dict_variables[pressure]}, method=\"nearest\") \n",
    "                              for pressure in list(plvls)], \n",
    "                             dim=\"pressure\") \n",
    "                   for var in list(params)], join='outer')\n",
    "\n",
    "    \n",
    "    # delayed write to file. Compute outside this function\n",
    "    \n",
    "    # lazy calculate indices\n",
    "    ds = calc_turbulence_indices(ds, which= turbulence_index, p=P, u=\"u\", v=\"v\", t=\"t\", z=\"z\",)\n",
    "\n",
    "    if outfile is None:\n",
    "        outfile = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\",\n",
    "\n",
    "    ds_to_write = ds[[turbulence_index]].sel({\"time\":str(year)})\n",
    "    try:\n",
    "        ds_to_write = ds_to_write.sel({\"pressure\":P}, method=\"nearest\",)\n",
    "    except:\n",
    "        pass\n",
    "    delayed_write = ds_to_write.to_netcdf(outfile, mode=\"a\", compute=False,)\n",
    "    return delayed_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb2748fa-f1ad-4589-b767-75841368ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate temporary turbulence index for baselines\n",
    "\n",
    "# best with one worker, many threads for barra\n",
    "# use 28 cores 4 threads, 2 workers\n",
    "\n",
    "\n",
    "# dict_years = {\"evaluation\":(1990, 2009), \n",
    "#               \"historical\":(1979, 2014), \n",
    "#               \"future\":(2015, 2100)}\n",
    "dict_model_index = {\"evaluation\":[\"evaluation_BARRA-R_r1i1p1f1\"], \n",
    "                    \"historical\":list_historical,\n",
    "                    \"future\":list_future}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0cdf6-456c-44b2-bc86-08e59e67ac74",
   "metadata": {},
   "source": [
    "## Calculate index for BARRA-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ec79e22-8085-4788-a19e-b3f6cf706ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "compute ... \n",
      "CPU times: user 63.1 ms, sys: 27.1 ms, total: 90.2 ms\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scenario =\"evaluation\"\n",
    "for run in dict_model_index[scenario]:\n",
    "    experiment_id, source_id, member_id = run.split(\"_\")        \n",
    "\n",
    "    p99_file = f\"/scratch/v46/gt3409/turbulence_AUSCAT/{turbulence_index}-{P}hPa-monthly-freq-above-p99_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "    percentile_file = f\"/scratch/v46/gt3409/turbulence_AUSCAT/{turbulence_index}-{P}hPa-monthly-percentiles_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "    if os.path.exists(p99_file) and os.path.exists(percentile_file):\n",
    "        print(f\"Files '{p99_file} and {percentile_file}' already exist.\")\n",
    "        continue\n",
    "    \n",
    "    with dask.config.set({\n",
    "        \"distributed.scheduler.locks.lease-timeout\": \"300s\",\n",
    "        \"distributed.scheduler.locks.lease-validation-interval\": \"30s\",\n",
    "    }):\n",
    "\n",
    "        with Client(threads_per_worker=4, n_workers=1) as client:\n",
    "            delayed_list=[]\n",
    "            for year in baseline_time_range:\n",
    "                os.makedirs(f\"/scratch/v46/gt3409/TMP_{turbulence_index}\", exist_ok=True)\n",
    "                new_file = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "                if os.path.exists(new_file):\n",
    "                    print(f\"File '{new_file}' already exists.\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Making {new_file}\")\n",
    "                delayed_list.append(delayed_turbulence_index(turbulence_index=turbulence_index,\n",
    "                                                             year=year,\n",
    "                                                             source_id=source_id,\n",
    "                                                             experiment_id=experiment_id,\n",
    "                                                             member_id=member_id,\n",
    "                                                             P=P,\n",
    "                                                             outfile=new_file,\n",
    "                                                            ))\n",
    "            print(\"compute ... \")\n",
    "            dask.compute(*delayed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe49257d-2287-4555-8bb0-b2590b68d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scenario =\"evaluation\"\n",
    "# for run in dict_model_index[scenario]:\n",
    "#     experiment_id, source_id, member_id = run.split(\"_\")     \n",
    "    \n",
    "#     for year in baseline_time_range:\n",
    "#         file = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "#         ds = xr.open_dataset(file)\n",
    "#         nulls = ds.isel({\"lat\":100, \"lon\":100})[turbulence_index].isnull().sum().values\n",
    "#         if nulls == 0:\n",
    "#             pass\n",
    "#         else:\n",
    "#             print(f\"nulls = {nulls} for {file}\")\n",
    "#             os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498bb7d-b9d0-46f3-aadd-6dc436a06782",
   "metadata": {},
   "source": [
    "## Define MOG p99 from BARRA-R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f45ba81f-396d-4505-b3c8-9c1399724eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p99 = 0.00978766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab0a452-3e0b-4c7b-b2ba-1a9a8f84aa90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.3 s, sys: 47 s, total: 1min 43s\n",
      "Wall time: 3min 4s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00978766])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# 20 year mid lat box p99 MOG\n",
    "\n",
    "# calculate p99, for windspeed-250hPa = 75.92640943\n",
    "# Determine threshold MOG from evaluation dataset\n",
    "run = \"evaluation_BARRA-R_r1i1p1f1\"\n",
    "experiment_id, source_id, member_id = run.split(\"_\")\n",
    "\n",
    "filelist = [f\"/scratch/v46/gt3409/TMP_{turbulence_index}/TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\" \n",
    " for year in baseline_time_range]\n",
    "\n",
    "def _preprocess(ds, q=[0.99],):\n",
    "    return ds.sel(lat=mid_lat_slice, lon=lon_slice).chunk({\"time\":-1, \"lat\":-1, \"lon\":-1}).quantile(q, dim=[\"time\", \"lat\", \"lon\"])\n",
    "\n",
    "ds = xr.open_mfdataset(filelist, decode_times=True, preprocess=_preprocess, combine=\"nested\", concat_dim=\"time\")\n",
    "# ds = ds.compute()\n",
    "\n",
    "nulls = ds[turbulence_index].isnull().sum().values\n",
    "assert nulls==0,  print(f\"nulls = {nulls}...\")\n",
    "\n",
    "p99 = ds.mean(\"time\")[turbulence_index].values\n",
    "p99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1afdc6-68cc-4ec3-8f9d-cb52a24193d8",
   "metadata": {},
   "source": [
    "# Now run all the calculations to make the files you need\n",
    "## Frequency above p99\n",
    "## and quantiles for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6140b585-e070-4a47-b00e-fdfaf4492940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 s, sys: 13 s, total: 21 s\n",
      "Wall time: 35.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# for all scenarios, calculate the index, then calculate the monthly frequency above the BARRA-R baseline 99th percentile\n",
    "# for baseline periods, also calculate the percentiles \n",
    "# output saved to /scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles\n",
    "# and /scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99\n",
    "# TMP files removed \n",
    "\n",
    "# best with one worker, many threads for barra\n",
    "# use 28 cores 4 threads, 2 workers\n",
    "\n",
    "dict_years = {\"evaluation\":(1990, 2009), \n",
    "              \"historical\":(1979, 2014), \n",
    "              \"future\":(2015, 2100)}\n",
    "dict_model_index = {\"evaluation\":[\"evaluation_BARRA-R_r1i1p1f1\"], \n",
    "                    \"historical\":list_historical,\n",
    "                    \"future\":list_future}\n",
    "\n",
    "def p99freq_preprocess(ds):\n",
    "    \"\"\"Calculate annual frequency of exceeding p99 threshold\"\"\"\n",
    "    return (ds>p99).resample({\"time\":\"ME\"},).mean([\"time\"], skipna=True)\n",
    "\n",
    "def quantiles_preprocess(ds):\n",
    "    \"\"\"For evaluation from historical, calculate the monthly values of 1st to 99th quantiles within the mid lat box\"\"\"\n",
    "    ds = ds.convert_calendar(\"standard\")\n",
    "    # rechunk such that there are as many chunks as there are years, \n",
    "    ds = ds.chunk({\"time\": -1, \"lat\": -1, \"lon\": -1})\n",
    "    ds = ds.sel(lat=mid_lat_slice, lon=lon_slice)\\\n",
    "            .resample(time=\"ME\")\\\n",
    "            .apply(lambda ds: ds.quantile(np.arange(0,1,0.01), dim=[\"lat\", \"lon\", \"time\"]))\n",
    "    return ds\n",
    "\n",
    "\n",
    "# with Client(threads_per_worker=4, n_workers=2) as client:\n",
    "#     for scenario in [ \"historical\", \"future\", \"evaluation\", ]:\n",
    "#         # start_year, end_year = dict_years[scenario]\n",
    "#         for run in dict_model_index[scenario]:\n",
    "#             experiment_id, source_id, member_id = run.split(\"_\")   \n",
    "#             os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa\", exist_ok=True)\n",
    "#             os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99\", exist_ok=True)\n",
    "#             p99_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99/\\\n",
    "# {turbulence_index}-{P}hPa-monthly-freq-above-p99_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "            \n",
    "#             if scenario ==\"historical\" or scenario==\"evaluation\":\n",
    "#                 frequency = \"monthly\"\n",
    "#                 perc_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles/\\\n",
    "# {turbulence_index}-{P}hPa-{frequency}-percentiles_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "#                 perc_filename_exists = os.path.exists(perc_filename)\n",
    "#             else:\n",
    "#                 perc_filename_exists = True\n",
    "            \n",
    "#             if os.path.exists(p99_filename) and perc_filename_exists:\n",
    "#                 print(f\"{p99_filename} already exists, skipping {run}\")\n",
    "#                 continue\n",
    "    \n",
    "#             delayed_list=[]\n",
    "#             start_year, end_year = dict_years[scenario]\n",
    "#             for year in np.arange(start_year, end_year+1):\n",
    "#                 tmp_file = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "# TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "#                 if os.path.exists(tmp_file):\n",
    "#                     print(f\"File '{tmp_file}' already exists.\")\n",
    "#                 else:\n",
    "#                     print(f\"Making {tmp_file}\")\n",
    "#                     delayed_list.append(delayed_turbulence_index(turbulence_index=turbulence_index,\n",
    "#                                                           year=year,\n",
    "#                                                           source_id=source_id,\n",
    "#                                                           experiment_id=experiment_id,\n",
    "#                                                           member_id=member_id,\n",
    "#                                                                  P=P,\n",
    "#                                                                  outfile=tmp_file\n",
    "#                                                                 ))\n",
    "                    \n",
    "#             if len(delayed_list)>0:\n",
    "#                 print(\"compute ... \")\n",
    "#                 dask.compute(*delayed_list)\n",
    "    \n",
    "#             # compute freq\n",
    "#             # multi years\n",
    "#             filelist = [f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "# TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\" \n",
    "#                         for year in np.arange(start_year, end_year+1)]\n",
    "            \n",
    "#             if os.path.exists(p99_filename):\n",
    "#                 print(f\"File '{p99_filename}' already exists.\")\n",
    "                \n",
    "#             else:\n",
    "#                 # calculate monthly freq above p99\n",
    "#                 ds =  xr.open_mfdataset(filelist,\n",
    "#                                        preprocess=p99freq_preprocess, \n",
    "#                                        combine=\"nested\", \n",
    "#                                        concat_dim=\"time\",\n",
    "#                                        )\\\n",
    "#                     .assign_coords({\"run\":run})\\\n",
    "#                     .to_netcdf(p99_filename, compute=True)\n",
    "#                 print(f\"made {p99_filename}\")\n",
    "    \n",
    "#             if scenario ==\"historical\" or scenario==\"evaluation\":\n",
    "#                 # calculate quantiles for evaluation period only\n",
    "#                 frequency = \"monthly\"\n",
    "#                 os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles\", exist_ok=True)\n",
    "#                 perc_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles/\\\n",
    "# {turbulence_index}-{P}hPa-{frequency}-percentiles_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "#                 if os.path.exists(perc_filename):\n",
    "#                     print(f\"File '{perc_filename}' already exists.\")\n",
    "#                 else:\n",
    "#                     filelist_baseline = [f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "# TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "#                                 for year in baseline_time_range]\n",
    "                    \n",
    "#                     ds = xr.open_mfdataset(filelist_baseline, \n",
    "#                                            combine=\"nested\", \n",
    "#                                            concat_dim=\"time\",\n",
    "#                                            preprocess=quantiles_preprocess,\n",
    "#                                           )\\\n",
    "#                             .assign_coords({\"run\":run})\n",
    "#                     null= ds.isnull()[turbulence_index].sum().values\n",
    "#                     # assert null==0, print(f\"Number of null values: {null} in {run}.\")\n",
    "                    \n",
    "#                     try:\n",
    "#                         ds.to_netcdf(perc_filename, compute=True)\n",
    "#                         print(f\"Made '{perc_filename}'\")\n",
    "#                     except Exception as e:\n",
    "#                         print(f\"Error in {run}: {e}\")\n",
    "               \n",
    "                    \n",
    "    \n",
    "#             # check that freq calculated correctly\n",
    "#             # then delete all in filelist\n",
    "#             for file in filelist:\n",
    "#                 if os.path.exists(file):\n",
    "#                     os.remove(file)\n",
    "#                     print(f\"File removed: {file}\")\n",
    "#                 else:\n",
    "#                     print(f\"File does not exist: {file}\")\n",
    "#                     pass\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5cd716e-4374-44ef-92f4-94767117c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_p99freq_and_quantiles(scenario):\n",
    "    \"\"\"expects scenario as one of  [ \"historical\", \"future\", \"evaluation\", ]\"\"\"\n",
    "    for run in dict_model_index[scenario]:\n",
    "        experiment_id, source_id, member_id = run.split(\"_\")   \n",
    "        os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa\", exist_ok=True)\n",
    "        os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99\", exist_ok=True)\n",
    "        p99_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99/\\\n",
    "{turbulence_index}-{P}hPa-monthly-freq-above-p99_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "        \n",
    "        if scenario ==\"historical\" or scenario==\"evaluation\":\n",
    "            frequency = \"monthly\"\n",
    "            perc_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles/\\\n",
    "{turbulence_index}-{P}hPa-{frequency}-percentiles_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "            perc_filename_exists = os.path.exists(perc_filename)\n",
    "        else:\n",
    "            perc_filename_exists = True\n",
    "        \n",
    "        if os.path.exists(p99_filename) and perc_filename_exists:\n",
    "            print(f\"{p99_filename} already exists, skipping {run}\")\n",
    "            continue\n",
    "\n",
    "        delayed_list=[]\n",
    "        start_year, end_year = dict_years[scenario]\n",
    "        for year in np.arange(start_year, end_year+1):\n",
    "            tmp_file = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "            if os.path.exists(tmp_file):\n",
    "                print(f\"File '{tmp_file}' already exists.\")\n",
    "            else:\n",
    "                print(f\"Making {tmp_file}\")\n",
    "                delayed_list.append(delayed_turbulence_index(turbulence_index=turbulence_index,\n",
    "                                                      year=year,\n",
    "                                                      source_id=source_id,\n",
    "                                                      experiment_id=experiment_id,\n",
    "                                                      member_id=member_id,\n",
    "                                                             P=P,\n",
    "                                                             outfile=tmp_file\n",
    "                                                            ))\n",
    "                \n",
    "        if len(delayed_list)>0:\n",
    "            print(\"compute ... \")\n",
    "            dask.compute(*delayed_list)\n",
    "\n",
    "        # compute freq\n",
    "        # multi years\n",
    "        filelist = [f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\" \n",
    "                    for year in np.arange(start_year, end_year+1)]\n",
    "        \n",
    "        if os.path.exists(p99_filename):\n",
    "            print(f\"File '{p99_filename}' already exists.\")\n",
    "            \n",
    "        else:\n",
    "            # calculate monthly freq above p99\n",
    "            ds =  xr.open_mfdataset(filelist,\n",
    "                                   preprocess=p99freq_preprocess, \n",
    "                                   combine=\"nested\", \n",
    "                                   concat_dim=\"time\",\n",
    "                                   )\\\n",
    "                .assign_coords({\"run\":run})\\\n",
    "                .to_netcdf(p99_filename, compute=True)\n",
    "            print(f\"made {p99_filename}\")\n",
    "\n",
    "        if scenario ==\"historical\" or scenario==\"evaluation\":\n",
    "            # calculate quantiles for evaluation period only\n",
    "            frequency = \"monthly\"\n",
    "            os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles\", exist_ok=True)\n",
    "            perc_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles/\\\n",
    "{turbulence_index}-{P}hPa-{frequency}-percentiles_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "            if os.path.exists(perc_filename):\n",
    "                print(f\"File '{perc_filename}' already exists.\")\n",
    "            else:\n",
    "                filelist_baseline = [f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "                            for year in baseline_time_range]\n",
    "                \n",
    "                ds = xr.open_mfdataset(filelist_baseline, \n",
    "                                       combine=\"nested\", \n",
    "                                       concat_dim=\"time\",\n",
    "                                       preprocess=quantiles_preprocess,\n",
    "                                      )\\\n",
    "                        .assign_coords({\"run\":run})\n",
    "                null= ds.isnull()[turbulence_index].sum().values\n",
    "                # assert null==0, print(f\"Number of null values: {null} in {run}.\")\n",
    "                \n",
    "                try:\n",
    "                    ds.to_netcdf(perc_filename, compute=True)\n",
    "                    print(f\"Made '{perc_filename}'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in {run}: {e}\")\n",
    "           \n",
    "                \n",
    "\n",
    "        # check that freq calculated correctly\n",
    "        # then delete all in filelist\n",
    "        for file in filelist:\n",
    "            if os.path.exists(file):\n",
    "                os.remove(file)\n",
    "                print(f\"File removed: {file}\")\n",
    "            else:\n",
    "                print(f\"File does not exist: {file}\")\n",
    "                pass\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c27ab-34d0-4a5d-a590-6bdd3e917dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_evaluation_BARRA-R_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping evaluation_BARRA-R_r1i1p1f1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n",
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/distributed/diagnostics/nvml.py:14: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_historical_ACCESS-CM2_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping historical_ACCESS-CM2_r4i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_historical_ACCESS-ESM1-5_r6i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping historical_ACCESS-ESM1-5_r6i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_historical_CESM2_r11i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping historical_CESM2_r11i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_historical_CMCC-ESM2_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping historical_CMCC-ESM2_r1i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_historical_EC-Earth3_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping historical_EC-Earth3_r1i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_historical_MPI-ESM1-2-HR_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping historical_MPI-ESM1-2-HR_r1i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_historical_NorESM2-MM_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping historical_NorESM2-MM_r1i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_ssp126_ACCESS-CM2_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping ssp126_ACCESS-CM2_r4i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_ssp126_ACCESS-ESM1-5_r6i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping ssp126_ACCESS-ESM1-5_r6i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_ssp126_CESM2_r11i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping ssp126_CESM2_r11i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_ssp126_CMCC-ESM2_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping ssp126_CMCC-ESM2_r1i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_ssp126_EC-Earth3_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping ssp126_EC-Earth3_r1i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_ssp126_MPI-ESM1-2-HR_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping ssp126_MPI-ESM1-2-HR_r1i1p1f1\n",
      "/scratch/v46/gt3409/VWS/200hPa/freq-above-p99/VWS-200hPa-monthly-freq-above-p99_AUS-15_ssp126_NorESM2-MM_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr.nc already exists, skipping ssp126_NorESM2-MM_r1i1p1f1\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2015.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2016.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2017.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2018.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2019.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2020.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2021.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2022.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2023.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2024.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2025.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2026.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2027.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2028.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2029.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2030.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2031.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2032.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2033.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2034.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2035.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2036.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2037.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2038.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2039.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2040.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2041.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2042.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2043.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2044.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2045.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2046.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2047.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2048.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2049.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2050.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2051.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2052.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2053.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2054.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2055.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2056.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2057.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2058.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2059.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2060.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2061.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2062.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2063.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2064.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2065.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2066.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2067.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2068.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2069.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2070.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2071.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2072.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2073.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2074.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2075.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2076.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2077.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2078.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2079.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2080.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2081.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2082.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2083.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2084.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2085.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2086.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2087.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2088.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2089.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2090.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2091.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2092.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2093.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2094.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2095.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2096.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2097.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2098.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2099.nc\n",
      "Making /scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2100.nc\n",
      "compute ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-22 21:38:26,411 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2098.nc', lease_id='c761e88518c844e3b7af51e8a3515d5a'. This can happen if the Lock or Semaphore timed out before.\n",
      "2026-01-22 21:40:11,061 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2070.nc', lease_id='12550df131244f78ae34de99694b0635'. This can happen if the Lock or Semaphore timed out before.\n",
      "2026-01-22 21:47:13,411 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2090.nc', lease_id='de608552a9b047a7abbdcc68fd4c15e7'. This can happen if the Lock or Semaphore timed out before.\n",
      "2026-01-22 21:47:52,143 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2040.nc', lease_id='736a1b6dc3de4391b60be9aa100855b7'. This can happen if the Lock or Semaphore timed out before.\n",
      "2026-01-22 21:52:43,890 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2031.nc', lease_id='d4b4f3a17f7f47849340b46b59aa4d59'. This can happen if the Lock or Semaphore timed out before.\n",
      "2026-01-22 21:53:05,870 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2052.nc', lease_id='21cd617993b34e54afab960ca565cf45'. This can happen if the Lock or Semaphore timed out before.\n",
      "2026-01-22 21:56:20,717 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2091.nc', lease_id='c8292445b23b4c17bb66ed1da6ec5614'. This can happen if the Lock or Semaphore timed out before.\n",
      "2026-01-22 21:56:46,100 - tornado.application - ERROR - Uncaught exception GET /individual-workers-memory/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-workers-memory/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:56:46,111 - tornado.application - ERROR - Uncaught exception GET /individual-task-stream/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-task-stream/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:56:46,116 - tornado.application - ERROR - Uncaught exception GET /individual-progress/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-progress/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:56:48,278 - tornado.application - ERROR - Uncaught exception GET /individual-progress/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-progress/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:56:48,284 - tornado.application - ERROR - Uncaught exception GET /individual-workers-memory/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-workers-memory/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:56:48,287 - tornado.application - ERROR - Uncaught exception GET /individual-task-stream/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-task-stream/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:56:53,319 - tornado.application - ERROR - Uncaught exception GET /individual-progress/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-progress/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:56:53,327 - tornado.application - ERROR - Uncaught exception GET /individual-task-stream/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-task-stream/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:56:53,331 - tornado.application - ERROR - Uncaught exception GET /individual-workers-memory/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-workers-memory/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:57:02,282 - tornado.application - ERROR - Uncaught exception GET /individual-progress/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-progress/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:57:02,285 - tornado.application - ERROR - Uncaught exception GET /individual-task-stream/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-task-stream/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:57:02,288 - tornado.application - ERROR - Uncaught exception GET /individual-workers-memory/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-workers-memory/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:57:18,358 - tornado.application - ERROR - Uncaught exception GET /individual-progress/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-progress/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:57:18,366 - tornado.application - ERROR - Uncaught exception GET /individual-task-stream/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-task-stream/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:57:18,368 - tornado.application - ERROR - Uncaught exception GET /individual-workers-memory/ws (127.0.0.1)\n",
      "HTTPServerRequest(protocol='http', host='gadi-cpu-bdw-0602.gadi.nci.org.au:5338', method='GET', uri='/individual-workers-memory/ws', version='HTTP/1.1', remote_ip='127.0.0.1')\n",
      "Traceback (most recent call last):\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/websocket.py\", line 965, in _accept_connection\n",
      "    open_result = handler.open(*handler.open_args, **handler.open_kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/tornado/web.py\", line 3375, in wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/g/data/xp65/public/apps/med_conda/envs/analysis3-25.12/lib/python3.11/site-packages/bokeh/server/views/ws.py\", line 149, in open\n",
      "    raise ProtocolError(\"Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\")\n",
      "bokeh.protocol.exceptions.ProtocolError: Token is expired. Configure the app with a larger value for --session-token-expiration if necessary\n",
      "2026-01-22 21:58:34,510 - distributed.semaphore - WARNING - Tried to release Lock or Semaphore but it was already released: name='/scratch/v46/gt3409/TMP_VWS/TMP_VWS-200hPa_AUS-15_ACCESS-CM2_ssp370_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_2086.nc', lease_id='7c624e0a93374c5da00338a978bec973'. This can happen if the Lock or Semaphore timed out before.\n"
     ]
    }
   ],
   "source": [
    "with Client(threads_per_worker=4, n_workers=1) as client:\n",
    "    for scenario in [ \"evaluation\",]:\n",
    "        run_p99freq_and_quantiles(scenario)\n",
    "\n",
    "with Client(threads_per_worker=4, n_workers=2) as client:\n",
    "    for scenario in [ \"historical\", \"future\",]:\n",
    "        run_p99freq_and_quantiles(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa74551-a2e0-4435-8680-da9ec3c943c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

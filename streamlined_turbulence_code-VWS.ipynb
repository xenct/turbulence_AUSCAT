{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9476eee7-85ed-49ef-891a-14b6a30bdbfd",
   "metadata": {},
   "source": [
    "# This notebook processes, evaluates, and plots Clear Air Turbulence indices for BARPA-R and BARRA-R "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a38098-5c9b-4664-b4a6-aee05730e1aa",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ad60213-5b21-4927-9b83-6d48956a171a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import glob\n",
    "import intake\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import xesmf as xe\n",
    "import inspect\n",
    "import calendar\n",
    "import pandas as pd\n",
    "from turbulence_AUSCAT.cat_indices import calc_turbulence_indices, windspeed, VWS, TI1\n",
    "from xarray.groupers import SeasonResampler\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"flox\").setLevel(logging.WARNING)\n",
    "\n",
    "from plotting_maps.acs_plotting_maps import plot_acs_hazard_multi, plot_acs_hazard, plot_data, cmap_dict, regions_dict\n",
    "from matplotlib import colors, cm\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "# ProgressBar().register()\n",
    "\n",
    "import dask\n",
    "from dask.distributed import Client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b32e2a-f432-4c3d-881c-58c523d83531",
   "metadata": {},
   "source": [
    "# Choose index to process and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab1bad86-33ab-48c9-a7c8-33d92d686189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# once you have adjusted this cell. All following cells should run smoothly \n",
    "# ensure you have requested lots of memory. It has been set up for are.nci.org.au 28 Cores with 126G memory\n",
    "turbulence_index = \"TI1\"\n",
    "\n",
    "P=250\n",
    "p=P\n",
    "p0 = P-50\n",
    "p1 = P+50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c984dd32-108c-47b3-9d46-7d9bfeebab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_lat_slice = slice(-50,-25)\n",
    "lon_slice = slice(90,195)\n",
    "\n",
    "baseline_time_range = np.arange(1990,2009+1)\n",
    "baseline_time_slice = slice(\"1990\", \"2009\")\n",
    "\n",
    "P0 = 1000\n",
    "step_size=  0.1545\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5917ed-1fa9-47ee-85c0-df481a1521b6",
   "metadata": {},
   "source": [
    "# Prepare BARRA-R data for baseline evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3424a58f-818d-438a-b795-e9829110285f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = xr.open_dataset(\"/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc\")\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae6e4da5-b778-45bd-b531-001e9f4ac7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_target = xr.open_dataset(\n",
    "    f\"/g/data/py18/BARPA/output/CMIP6/DD/AUS-15/BOM/ACCESS-CM2/historical/r4i1p1f1/BARPA-R/v1-r1/6hr/ua{P}/v20231001/\\\n",
    "ua{P}_AUS-15_ACCESS-CM2_historical_r4i1p1f1_BOM_BARPA-R_v1-r1_6hr_196001-196012.nc\")\\\n",
    ".drop_vars(\"pressure\").chunk({\"time\":120, \"lat\":-1, \"lon\":-1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7ed0570-07ce-4ab5-bdb7-ef5ded7011b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ua_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_va_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_zg_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc' already exists.\n",
      "File '/scratch/v46/gt3409/BARRA-R/TMP_ta_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc' already exists.\n",
      "CPU times: user 2.62 s, sys: 4.63 s, total: 7.26 s\n",
      "Wall time: 7.38 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# best with one thread per worker\n",
    "# takes about 12 hours with 28 cores\n",
    "VARU = \"wnd_ucmp\"\n",
    "VARV = \"wnd_vcmp\"\n",
    "VART = \"air_temp\"\n",
    "VARZ = \"geop_ht\"\n",
    "\n",
    "barra_vars = {\"wnd_ucmp\":\"ua\", \"wnd_vcmp\": \"va\", \"air_temp\":\"ta\", \"geop_ht\":\"zg\"}\n",
    "\n",
    "# start and end for BARRA-R specifically\n",
    "lat_min, lat_max, lon_min, lon_max = (ds_target[\"lat\"].values[0], ds_target[\"lat\"].values[-1], \n",
    "                                      ds_target[\"lon\"].values[0], ds_target[\"lon\"].values[-1])\n",
    "regridder=None\n",
    "\n",
    "def _preprocess(ds):\n",
    "    ds = ds.drop_vars( [\"latitude_longitude\"],)\\\n",
    "            .sel({\"latitude\": slice(lat_min-0.2 , lat_max+0.2), \"longitude\":slice(lon_min-0.2 , lon_max+0.2)})\\\n",
    "            .sel({\"pressure\":[100, 150, 200, 250, 300,]},  method = \"nearest\")\n",
    "            # .sel({\"pressure\":[p0,p,p1]},  method = \"nearest\")\n",
    "    try:\n",
    "        ds = ds.drop_vars([\"forecast_period\", \"forecast_reference_time\",])\n",
    "    except:\n",
    "        pass\n",
    "    return ds  \n",
    "\n",
    "with Client(threads_per_worker=1, n_workers=40) as client:\n",
    "    # retry loop because sometimes this loop fails (randomly?) and can be resolved by simply retrying\n",
    "    max_retries = 10\n",
    "    retry_count = 0\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            ds = None\n",
    "            for VAR in [VARU, VARV, VARZ, VART]:\n",
    "                regridder = None\n",
    "                for year in baseline_time_range:\n",
    "                    new_file = f\"/scratch/v46/gt3409/BARRA-R/TMP_{barra_vars[VAR]}_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "                    if os.path.exists(new_file):\n",
    "                        print(f\"File '{new_file}' already exists.\")\n",
    "                        continue\n",
    "                        \n",
    "                    filelist = glob.glob(f\"/g/data/cj37/BARRA/BARRA_R/v1/analysis/prs/{VAR}/{year}/*/{VAR}-an-prs-PT0H-BARRA_R-v1-*T*00Z.sub.nc\")\n",
    "                    filelist.sort()\n",
    "                \n",
    "                    print(f\"open_mfdataset {VAR} {year}...\")\n",
    "                    ds = xr.open_mfdataset(filelist, preprocess=_preprocess, combine=\"nested\", concat_dim=\"time\", \n",
    "                                           parallel=True, decode_timedelta=False)\\\n",
    "                            .rename({\"latitude\":\"lat\", \"longitude\":\"lon\", VAR:barra_vars[VAR]})\\\n",
    "                            .chunk({\"pressure\":1, \"time\":120, \"lat\":-1, \"lon\":-1})\n",
    "    \n",
    "                    if regridder is None:\n",
    "                        print(\"calculate regridder...\")\n",
    "                        regridder = xe.Regridder(ds, ds_target, \"bilinear\",)\n",
    "                    print(f\"regrid and compute {year}...\")\n",
    "                    ds_regridded = regridder(ds)\n",
    "                    # for plvl in [p0, p, p1]:\n",
    "                    new_file = f\"/scratch/v46/gt3409/BARRA-R/TMP_{barra_vars[VAR]}_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"                   \n",
    "                    try:\n",
    "                        print(\"saving netcdf...\")\n",
    "                        # ds_regridded.sel({\"pressure\":plvl}, method=\"nearest\").to_netcdf(new_file)\n",
    "                        ds_regridded.to_netcdf(new_file, engine=\"h5netcdf\", encoding = {barra_vars[VAR]:{\"zlib\": True, \"complevel\": 6,}})\n",
    "                        # ds_regridded.to_netcdf(new_file,)\n",
    "                        print(f\"Saved {new_file}\")\n",
    "                        \n",
    "                        # check for any nulls\n",
    "                        ds = xr.open_dataset(new_file)\n",
    "                        nulls = ds.isel({\"pressure\":0, \"lat\":0, \"lon\":0})[barra_vars[VAR]].isnull().sum().values\n",
    "                        print(f\"nulls = {nulls} for {new_file}\")\n",
    "                        if nulls == 0:\n",
    "                            pass\n",
    "                        else:\n",
    "                            os.remove(new_file)\n",
    "                            print(f\"nulls found. Removed file: {new_file}\")\n",
    "                            break    \n",
    "                    except:\n",
    "                        # os.remove(new_file)\n",
    "                        print(f\"Problem saving {new_file}\")\n",
    "                        break\n",
    "                    ds.close()\n",
    "                    ds_regridded.close()  \n",
    "                \n",
    "        except:\n",
    "            retry_count += 1\n",
    "            print(f\"Error. Retry count = {retry_count}\")\n",
    "        break\n",
    "    else:\n",
    "        print(f\"Operation failed after {max_retries} attempts.\")\n",
    "            \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594a4026-d89d-45d7-9c18-355fb35bd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a2da6e-b2e5-48e3-a275-2fc7c6d20ba5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wnd_ucmp\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "wnd_vcmp\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "geop_ht\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "air_temp\n",
      "1990\n",
      "1991\n",
      "1992\n",
      "1993\n",
      "1994\n",
      "1995\n",
      "1996\n",
      "1997\n",
      "1998\n",
      "1999\n",
      "2000\n",
      "2001\n",
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "CPU times: user 44.4 s, sys: 4.8 s, total: 49.2 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Test BARRA-R core variables for nans.\n",
    "# If there are nans, (you may need to remove dependent files that have nans) \n",
    "# restart this notebook and run the code again.\n",
    "for VAR in [VARU, VARV, VARZ, VART]:\n",
    "    print(VAR)\n",
    "    for year in baseline_time_range:\n",
    "        file = f\"/scratch/v46/gt3409/BARRA-R/TMP_{barra_vars[VAR]}_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "        print(year)\n",
    "        ds = xr.open_dataset(file)\n",
    "        nulls = ds.isel({\"pressure\":0, \"lat\":0, \"lon\":0})[barra_vars[VAR]].isnull().sum().values\n",
    "        if nulls == 0:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"nulls = {nulls} for {file}. Removing ...\")\n",
    "            os.remove(file)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3baf896-e00e-4a47-8755-ee967b34861c",
   "metadata": {},
   "source": [
    "# Identify available BARPA-R experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3af0a83a-f4fb-4763-b1d9-b8db3c20198b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "activity_id                                                    [BARPA-R]\n",
       "institution_id                                                     [BOM]\n",
       "version                                                      [v20231001]\n",
       "variable_id            [ta200, ta250, ta300, ua200, ua250, ua300, va2...\n",
       "table_id                                                           [6hr]\n",
       "source_id              [ACCESS-CM2, ACCESS-ESM1-5, CESM2, CMCC-ESM2, ...\n",
       "experiment_id           [historical, ssp126, ssp370, ssp585, evaluation]\n",
       "member_id                      [r4i1p1f1, r6i1p1f1, r11i1p1f1, r1i1p1f1]\n",
       "grid_label                                                      [AUS-15]\n",
       "time_range             [196001-196012, 196101-196112, 196201-196212, ...\n",
       "path                   [/g/data/py18/BARPA/output/CMIP6/DD/AUS-15/BOM...\n",
       "derived_variable_id                                                   []\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get information of available datasets\n",
    "\n",
    "cat_name = \"barpa\"\n",
    "col = intake.open_esm_datastore(f\"/g/data/lp01/collections/py3.9_dev/nci-{cat_name}.json\")\n",
    "\n",
    "var_list = [f\"{var}{pressure}\" for var in [\"ta\", \"ua\", \"va\", \"zg\"] for pressure in [P-50, P, P+50]]\n",
    "\n",
    "table_id = \"6hr\"\n",
    "scenarios = [\"historical\",\"ssp126\", \"ssp370\", \"ssp585\", \"evaluation\"]\n",
    "\n",
    "# change this query to select a subset of the data you are interested in\n",
    "query = dict(variable_id = var_list,\n",
    "             table_id = table_id,\n",
    "             experiment_id = scenarios,\n",
    "            )\n",
    "\n",
    "cat = col.search(**query)\n",
    "cat.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b818cb9e-6b82-42a5-b471-bdc992d22e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df_max = cat.df.groupby([\"variable_id\", \"experiment_id\", \"source_id\", \"member_id\"]).max().reset_index()\n",
    "# cat_df_max[\"index\"] = cat_df_max.variable_id + \"_\" + cat_df_max.experiment_id + \"_\" + cat_df_max.source_id + \"_\" + cat_df_max.member_id\n",
    "cat_df_max[\"index\"] = [f'{cat_df_max.iloc[i][\"experiment_id\"]}_{cat_df_max.iloc[i][\"source_id\"]}_{cat_df_max.iloc[i][\"member_id\"]}' for i in np.arange(len(cat_df_max))]\n",
    "cat_df_max = cat_df_max.set_index(\"index\")\n",
    "\n",
    "\n",
    "# indices for evaluation, historical and future groups. These will share time ranges\n",
    "i_evaluation = cat_df_max.loc[cat_df_max[\"experiment_id\"].isin([\"evaluation\"])].index\n",
    "i_historical = cat_df_max.loc[cat_df_max[\"experiment_id\"].isin([\"historical\"])].index\n",
    "i_future = cat_df_max.loc[cat_df_max[\"experiment_id\"].isin([\"ssp126\", \"ssp370\", \"ssp585\"])].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a6def7-a7df-4c75-936c-141a5613d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_evaluation = ['evaluation_BARRA-R_r1i1p1f1',\n",
    "                  ]\n",
    "\n",
    "list_historical = ['historical_ACCESS-CM2_r4i1p1f1', \n",
    "                   'historical_ACCESS-ESM1-5_r6i1p1f1',\n",
    "                   'historical_CESM2_r11i1p1f1', \n",
    "                   'historical_CMCC-ESM2_r1i1p1f1',\n",
    "                   'historical_EC-Earth3_r1i1p1f1',\n",
    "                   'historical_MPI-ESM1-2-HR_r1i1p1f1',\n",
    "                   'historical_NorESM2-MM_r1i1p1f1',\n",
    "                  ]\n",
    "\n",
    "list_ssp126 = [\n",
    "                 'ssp126_ACCESS-CM2_r4i1p1f1', \n",
    "                 'ssp126_ACCESS-ESM1-5_r6i1p1f1',\n",
    "                 'ssp126_CESM2_r11i1p1f1',\n",
    "                 'ssp126_CMCC-ESM2_r1i1p1f1',\n",
    "                 'ssp126_EC-Earth3_r1i1p1f1',\n",
    "                 'ssp126_MPI-ESM1-2-HR_r1i1p1f1',\n",
    "                 'ssp126_NorESM2-MM_r1i1p1f1',\n",
    "              ]\n",
    "\n",
    "list_ssp370 = ['ssp370_ACCESS-CM2_r4i1p1f1',\n",
    "                 'ssp370_ACCESS-ESM1-5_r6i1p1f1',\n",
    "                 'ssp370_CESM2_r11i1p1f1',\n",
    "                 'ssp370_CMCC-ESM2_r1i1p1f1',\n",
    "                 'ssp370_EC-Earth3_r1i1p1f1',\n",
    "                 'ssp370_MPI-ESM1-2-HR_r1i1p1f1',\n",
    "                 'ssp370_NorESM2-MM_r1i1p1f1',\n",
    "              ]\n",
    "\n",
    "list_ssp585 = ['ssp585_ACCESS-CM2_r4i1p1f1',\n",
    "                 'ssp585_EC-Earth3_r1i1p1f1']\n",
    "\n",
    "list_future = list_ssp126 + list_ssp370 + list_ssp585"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e76436-6bea-4e04-83f6-3ceab4ded607",
   "metadata": {},
   "source": [
    "# Calculate indices from standard variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdf1e47b-a263-4459-b213-6cc922429eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dti_preprocess(ds):\n",
    "    ds = ds.drop_vars([\"crs\"])\n",
    "    # ds = ds.dropna(\"time\") # too slow\n",
    "    ds = ds.convert_calendar(\"standard\")\n",
    "    try:\n",
    "        ds = ds.expand_dims({\"pressure\":[int(ds.variable_id[2:])]})\n",
    "    except:\n",
    "        pass\n",
    "    return ds\n",
    "    \n",
    "def delayed_turbulence_index(turbulence_index=None,\n",
    "                             year=None,\n",
    "                             path = \"/g/data/py18/BARPA/output/CMIP6/DD/AUS-15/BOM\",\n",
    "                             source_id=None,\n",
    "                             experiment_id=None,\n",
    "                             member_id=None,\n",
    "                             table_id = \"6hr\", \n",
    "                             version=\"v20231001\", \n",
    "                             P=250,\n",
    "                             outfile = None,\n",
    "                             chunks={\"time\":-1, \"lat\":-1, \"lon\":-1},\n",
    "                             ):\n",
    "    \"\"\"Use this function to compute the turbulence indices in a delayed routine\"\"\"\n",
    "    # get a list of the variables needed for calculating this turbulence index (var_list)\n",
    "    var_list = [f\"{var}{pressure}\" for var in [\"ta\", \"ua\", \"va\", \"zg\"] for pressure in [P-50, P, P+50]]\n",
    "    dict_variables = {\"t\":\"ta\",\"u\":\"ua\",\"v\":\"va\",\"z\":\"zg\",\n",
    "                      \"p\":int(P),\"p0\":int(P-50),\"p1\":int(P+50),}\n",
    "    inverted_dict = {value: key for key, value in dict_variables.items()}\n",
    "\n",
    "    def _filename(var, pressure, source_id, experiment_id):\n",
    "        VAR = f\"{dict_variables[var]}{dict_variables[pressure]}\"\n",
    "        if source_id == \"BARRA-R\" and experiment_id == \"evaluation\":\n",
    "            filename = f\"/scratch/v46/gt3409/BARRA-R/TMP_{dict_variables[var]}_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "        else:\n",
    "            filename = f\"{path}/{source_id}/{experiment_id}/{member_id}/BARPA-R/v1-r1/{table_id}/{VAR}/{version}/\\\n",
    "{VAR}_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}01-{year}12.nc\"\n",
    "        return filename\n",
    "\n",
    "    def _open_it(file):\n",
    "        ds = xr.open_dataset(file, decode_times=True, chunks = chunks)\\\n",
    "            .drop_vars([\"crs\"])\\\n",
    "            .astype(\"float32\")\\\n",
    "            .convert_calendar(\"standard\")\n",
    "\n",
    "        VAR=list(ds.variables)[0]\n",
    "        ds = ds.rename({VAR: inverted_dict[''.join(char for char in VAR if char.isalpha())]})\n",
    "        try:\n",
    "            ds = ds.expand_dims(\"pressure\")\n",
    "        except:\n",
    "            pass\n",
    "        ds[\"pressure\"] = ds[\"pressure\"].astype(\"int\")\n",
    "        return ds\n",
    "\n",
    "    turbulence_index_vars = set()\n",
    "    turbulence_index_vars.update(list(inspect.signature(globals()[turbulence_index]).parameters.keys()))\n",
    "    \n",
    "    params = turbulence_index_vars.intersection([\"t\", \"u\", \"v\", \"z\"])\n",
    "    plvls = turbulence_index_vars.intersection([\"p0\", \"p\", \"p1\", \"P0\"])\n",
    "    if len(plvls)==0:\n",
    "        plvls=set([\"p\"])\n",
    "    \n",
    "    var_list = [f\"{dict_variables[var]}{dict_variables[pressure]}\" for var in list(params) for pressure in list(plvls)]\n",
    "\n",
    "    \n",
    "    ds = xr.merge([xr.concat([_open_it(_filename(var, pressure, source_id, experiment_id)).sel({\"pressure\":dict_variables[pressure]}, method=\"nearest\") \n",
    "                              for pressure in list(plvls)], \n",
    "                             dim=\"pressure\") \n",
    "                   for var in list(params)], join='outer')\n",
    "    \n",
    "    # delayed write to file. Compute outside this function\n",
    "    \n",
    "    # lazy calculate indices\n",
    "    ds = calc_turbulence_indices(ds, which= turbulence_index, p=P, u=\"u\", v=\"v\", t=\"t\", z=\"z\",)\n",
    "\n",
    "    if outfile is None:\n",
    "        outfile = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\",\n",
    "\n",
    "    ds_to_write = ds[[turbulence_index]].sel({\"time\":str(year)})\n",
    "    try:\n",
    "        ds_to_write = ds_to_write.sel({\"pressure\":P}, method=\"nearest\",)\n",
    "    except:\n",
    "        pass\n",
    "    delayed_write = ds_to_write.to_netcdf(outfile, mode=\"a\", compute=False,)\n",
    "    return delayed_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb2748fa-f1ad-4589-b767-75841368ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate temporary turbulence index for baselines\n",
    "dict_model_index = {\"evaluation\":[\"evaluation_BARRA-R_r1i1p1f1\"], \n",
    "                    \"historical\":list_historical,\n",
    "                    \"future\":list_future}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0cdf6-456c-44b2-bc86-08e59e67ac74",
   "metadata": {},
   "source": [
    "## Calculate index for BARRA-R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec79e22-8085-4788-a19e-b3f6cf706ce3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1990.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1991.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1992.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1993.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1994.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1995.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1996.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1997.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1998.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_1999.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2000.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2001.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2002.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2003.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2004.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2005.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2006.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2007.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2008.nc\n",
      "Making /scratch/v46/gt3409/TMP_TI1/TMP_TI1-250hPa_AUS-15_BARRA-R_evaluation_r1i1p1f1_BOM_BARPA-R_v1-r1_6hr_2009.nc\n",
      "compute ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/xp65/public/apps/med_conda/envs/analysis3-26.01/lib/python3.11/site-packages/dask/_task_spec.py:759: RuntimeWarning: invalid value encountered in divide\n",
      "  return self.func(*new_argspec)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scenario =\"evaluation\"\n",
    "for run in dict_model_index[scenario]:\n",
    "    experiment_id, source_id, member_id = run.split(\"_\")        \n",
    "\n",
    "    p99_file = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99/{turbulence_index}-{P}hPa-monthly-freq-above-p99_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "    percentile_file = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles/{turbulence_index}-{P}hPa-monthly-percentiles_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "    # if os.path.exists(p99_file) and os.path.exists(percentile_file):\n",
    "    #     print(f\"Files '{p99_file} and {percentile_file}' already exist.\")\n",
    "    #     continue\n",
    "    \n",
    "    with dask.config.set({\n",
    "        \"distributed.scheduler.locks.lease-timeout\": \"300s\",\n",
    "        \"distributed.scheduler.locks.lease-validation-interval\": \"30s\",\n",
    "    }):\n",
    "\n",
    "        # with Client(threads_per_worker=2, n_workers=1) as client:\n",
    "        with Client(threads_per_worker=2, n_workers=1,  processes=True) as client:   \n",
    "            delayed_list=[]\n",
    "            for year in baseline_time_range:\n",
    "                os.makedirs(f\"/scratch/v46/gt3409/TMP_{turbulence_index}\", exist_ok=True)\n",
    "                new_file = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "                if os.path.exists(new_file):\n",
    "                    print(f\"File '{new_file}' already exists.\")\n",
    "                    continue\n",
    "                \n",
    "                print(f\"Making {new_file}\")\n",
    "                delayed_list.append(delayed_turbulence_index(turbulence_index=turbulence_index,\n",
    "                                                             year=year,\n",
    "                                                             source_id=source_id,\n",
    "                                                             experiment_id=experiment_id,\n",
    "                                                             member_id=member_id,\n",
    "                                                             P=P,\n",
    "                                                             outfile=new_file,\n",
    "                                                            ))\n",
    "            print(\"compute ... \")\n",
    "            dask.compute(*delayed_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe49257d-2287-4555-8bb0-b2590b68d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario =\"evaluation\"\n",
    "for run in dict_model_index[scenario]:\n",
    "    experiment_id, source_id, member_id = run.split(\"_\")     \n",
    "    \n",
    "    for year in baseline_time_range:\n",
    "        file = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "        ds = xr.open_dataset(file)\n",
    "        nulls = ds.isel({\"lat\":100, \"lon\":100})[turbulence_index].isnull().sum().values\n",
    "        if nulls == 0:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"nulls = {nulls} for {file}\")\n",
    "            os.remove(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498bb7d-b9d0-46f3-aadd-6dc436a06782",
   "metadata": {},
   "source": [
    "## Define MOG p99 from BARRA-R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ba81f-396d-4505-b3c8-9c1399724eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab0a452-3e0b-4c7b-b2ba-1a9a8f84aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 20 year mid lat box p99 MOG\n",
    "\n",
    "# calculate p99, for windspeed-250hPa = 75.92640943\n",
    "# Determine threshold MOG from evaluation dataset\n",
    "run = \"evaluation_BARRA-R_r1i1p1f1\"\n",
    "experiment_id, source_id, member_id = run.split(\"_\")\n",
    "\n",
    "filelist = [f\"/scratch/v46/gt3409/TMP_{turbulence_index}/TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\" \n",
    " for year in baseline_time_range]\n",
    "\n",
    "def _preprocess(ds, q=[0.99],):\n",
    "    return ds.sel(lat=mid_lat_slice, lon=lon_slice).chunk({\"time\":-1, \"lat\":-1, \"lon\":-1}).quantile(q, dim=[\"time\", \"lat\", \"lon\"])\n",
    "\n",
    "ds = xr.open_mfdataset(filelist, decode_times=True, preprocess=_preprocess, combine=\"nested\", concat_dim=\"time\")\n",
    "# ds = ds.compute()\n",
    "\n",
    "nulls = ds[turbulence_index].isnull().sum().values\n",
    "assert nulls==0,  print(f\"nulls = {nulls}...\")\n",
    "\n",
    "p99 = ds.mean(\"time\")[turbulence_index].values\n",
    "p99\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1afdc6-68cc-4ec3-8f9d-cb52a24193d8",
   "metadata": {},
   "source": [
    "# Now run all the calculations to make the files you need\n",
    "## Frequency above p99\n",
    "## and quantiles for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140b585-e070-4a47-b00e-fdfaf4492940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for all scenarios, calculate the index, then calculate the monthly frequency above the BARRA-R baseline 99th percentile\n",
    "# for baseline periods, also calculate the percentiles \n",
    "# output saved to /scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles\n",
    "# and /scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99\n",
    "# TMP files removed \n",
    "\n",
    "# best with one worker, many threads for barra\n",
    "# use 28 cores 4 threads, 2 workers\n",
    "\n",
    "dict_years = {\"evaluation\":(1990, 2009), \n",
    "              \"historical\":(1979, 2014), \n",
    "              \"future\":(2015, 2100)}\n",
    "dict_model_index = {\"evaluation\":[\"evaluation_BARRA-R_r1i1p1f1\"], \n",
    "                    \"historical\":list_historical,\n",
    "                    \"future\":list_future}\n",
    "\n",
    "def p99freq_preprocess(ds):\n",
    "    \"\"\"Calculate annual frequency of exceeding p99 threshold\"\"\"\n",
    "    return (ds>p99).resample({\"time\":\"ME\"},).mean([\"time\"], skipna=True)\n",
    "\n",
    "def quantiles_preprocess(ds):\n",
    "    \"\"\"For evaluation from historical, calculate the monthly values of 1st to 99th quantiles within the mid lat box\"\"\"\n",
    "    ds = ds.convert_calendar(\"standard\")\n",
    "    # rechunk such that there are as many chunks as there are years, \n",
    "    ds = ds.chunk({\"time\": 4*365, \"lat\": -1, \"lon\": -1})\n",
    "    ds = ds.sel(lat=mid_lat_slice, lon=lon_slice)\\\n",
    "            .resample(time=\"ME\")\\\n",
    "            .apply(lambda ds: ds.quantile(np.arange(0,1,0.01), dim=[\"lat\", \"lon\", \"time\"]))\n",
    "    return ds\n",
    "    \n",
    "def run_p99freq_and_quantiles(scenario, chunks={\"time\":-1, \"lat\":-1, \"lon\":-1}):\n",
    "    \"\"\"expects scenario as one of  [ \"historical\", \"future\", \"evaluation\", ]\"\"\"\n",
    "    for run in dict_model_index[scenario]:\n",
    "        experiment_id, source_id, member_id = run.split(\"_\")   \n",
    "        os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa\", exist_ok=True)\n",
    "        os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99\", exist_ok=True)\n",
    "        p99_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/freq-above-p99/\\\n",
    "{turbulence_index}-{P}hPa-monthly-freq-above-p99_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "        \n",
    "        if scenario ==\"historical\" or scenario==\"evaluation\":\n",
    "            frequency = \"monthly\"\n",
    "            perc_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles/\\\n",
    "{turbulence_index}-{P}hPa-{frequency}-percentiles_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "            perc_filename_exists = os.path.exists(perc_filename)\n",
    "        else:\n",
    "            perc_filename_exists = True\n",
    "        \n",
    "        if os.path.exists(p99_filename) and perc_filename_exists:\n",
    "            print(f\"{p99_filename} already exists, skipping {run}\")\n",
    "            continue\n",
    "\n",
    "        delayed_list=[]\n",
    "        start_year, end_year = dict_years[scenario]\n",
    "        for year in np.arange(start_year, end_year+1):\n",
    "            tmp_file = f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "            if os.path.exists(tmp_file):\n",
    "                print(f\"File '{tmp_file}' already exists.\")\n",
    "            else:\n",
    "                print(f\"Making {tmp_file}\")\n",
    "                delayed_list.append(delayed_turbulence_index(turbulence_index=turbulence_index,\n",
    "                                                      year=year,\n",
    "                                                      source_id=source_id,\n",
    "                                                      experiment_id=experiment_id,\n",
    "                                                      member_id=member_id,\n",
    "                                                             P=P,\n",
    "                                                             outfile=tmp_file,\n",
    "                                                             chunks=chunks,\n",
    "                                                            ))\n",
    "                \n",
    "        if len(delayed_list)>0:\n",
    "            print(\"compute ... \")\n",
    "            dask.compute(*delayed_list)\n",
    "\n",
    "        # compute freq\n",
    "        # multi years\n",
    "        filelist = [f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\" \n",
    "                    for year in np.arange(start_year, end_year+1)]\n",
    "        \n",
    "        if os.path.exists(p99_filename):\n",
    "            print(f\"File '{p99_filename}' already exists.\")\n",
    "            \n",
    "        else:\n",
    "            # calculate monthly freq above p99\n",
    "            ds =  xr.open_mfdataset(filelist,\n",
    "                                   preprocess=p99freq_preprocess, \n",
    "                                   combine=\"nested\", \n",
    "                                   concat_dim=\"time\",\n",
    "                                   )\\\n",
    "                .assign_coords({\"run\":run})\\\n",
    "                .assign_attrs({\"turbulence_index\": turbulence_index,\n",
    "                               \"pressure_level\": P,\n",
    "                               \"Description\": f\"Frequency of {turbulence_index} at {P}hPa above the 99th percentile for BARPA-R experiments based on BARRA-R from 1990 to 2009 within latitudes (-50 to -25) and longitudes (90 to 195) using 6-hourly data and calculating frequencies per calendar month\",\n",
    "                               \"p99\":p99,})\\\n",
    "                .to_netcdf(p99_filename, compute=True)\n",
    "            print(f\"made {p99_filename}\")\n",
    "\n",
    "        if scenario ==\"historical\" or scenario==\"evaluation\":\n",
    "            # calculate quantiles for evaluation period only\n",
    "            frequency = \"monthly\"\n",
    "            os.makedirs(f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles\", exist_ok=True)\n",
    "            perc_filename = f\"/scratch/v46/gt3409/{turbulence_index}/{P}hPa/percentiles/\\\n",
    "{turbulence_index}-{P}hPa-{frequency}-percentiles_AUS-15_{run}_BOM_BARPA-R_v1-r1_6hr.nc\"\n",
    "            if os.path.exists(perc_filename):\n",
    "                print(f\"File '{perc_filename}' already exists.\")\n",
    "            else:\n",
    "                filelist_baseline = [f\"/scratch/v46/gt3409/TMP_{turbulence_index}/\\\n",
    "TMP_{turbulence_index}-{P}hPa_AUS-15_{source_id}_{experiment_id}_{member_id}_BOM_BARPA-R_v1-r1_6hr_{year}.nc\"\n",
    "                            for year in baseline_time_range]\n",
    "                \n",
    "                ds = xr.open_mfdataset(filelist_baseline, \n",
    "                                       combine=\"nested\", \n",
    "                                       concat_dim=\"time\",\n",
    "                                       preprocess=quantiles_preprocess,\n",
    "                                      )\\\n",
    "                        .assign_coords({\"run\":run})\\\n",
    "                        .assign_attrs({\"turbulence_index\": turbulence_index,\n",
    "                                       \"pressure_level\": P,\n",
    "                                       \"Description\": f\"Percentiles of {turbulence_index} at {P}hPa for BARPA-R experiments using 6-hourly data and calculating frequencies per calendar month for years 1990 to 2009\",\n",
    "                                      })\n",
    "                null= ds.isnull()[turbulence_index].sum().values\n",
    "                # assert null==0, print(f\"Number of null values: {null} in {run}.\")\n",
    "                \n",
    "                try:\n",
    "                    ds.to_netcdf(perc_filename, compute=True)\n",
    "                    print(f\"Made '{perc_filename}'\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error in {run}: {e}\")\n",
    "\n",
    "        # check that freq calculated correctly\n",
    "        # then delete all in filelist\n",
    "        for file in filelist:\n",
    "            if os.path.exists(file):\n",
    "                os.remove(file)\n",
    "                print(f\"File removed: {file}\")\n",
    "            else:\n",
    "                print(f\"File does not exist: {file}\")\n",
    "                pass\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c27ab-34d0-4a5d-a590-6bdd3e917dfd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if turbulence_index == \"TI1\":\n",
    "    with Client(threads_per_worker=5, n_workers=2) as client:\n",
    "        for scenario in [ \"historical\", \"future\",]:\n",
    "            run_p99freq_and_quantiles(scenario, chunks={\"time\":240, \"lat\":-1, \"lon\":-1})\n",
    "    \n",
    "    with Client(threads_per_worker=5, n_workers=1) as client:\n",
    "        for scenario in [ \"evaluation\",]:\n",
    "            run_p99freq_and_quantiles(scenario, chunks={\"time\":240, \"lat\":-1, \"lon\":-1})\n",
    "else:        \n",
    "    with Client(threads_per_worker=4, n_workers=2) as client:\n",
    "        for scenario in [ \"historical\", \"future\",]:\n",
    "            run_p99freq_and_quantiles(scenario)\n",
    "    \n",
    "    with Client(threads_per_worker=4, n_workers=1) as client:\n",
    "        for scenario in [ \"evaluation\",]:\n",
    "            run_p99freq_and_quantiles(scenario)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
